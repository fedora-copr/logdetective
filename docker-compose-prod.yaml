services:
  llama-cpp:
    extends:
      file: docker-compose.yaml
      service: llama-cpp
    # these lines are needed for CUDA acceleration
    devices:
      - nvidia.com/gpu=all
  server:
    extends:
      file: docker-compose.yaml
      service: server
    environment:
      ENV: production
      LOGDETECTIVE_SERVER_PORT: 443
    ports:
      - 443:443
  postgres:
    extends:
      file: docker-compose.yaml
      service: postgres

volumes:
  database_data:
    driver: local
  matplotlib-config:
    driver: local
