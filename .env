# compose sources this file
# docs: https://docs.docker.com/compose/environment-variables/set-environment-variables/
ENV="devel"
LOGDETECTIVE_SERVER_PORT=8080
# for some reason, fastapi cripples sys.path and some deps cannot be found
PYTHONPATH=/src:/usr/local/lib64/python3.13/site-packages:/usr/lib64/python313.zip:/usr/lib64/python3.13/:/usr/lib64/python3.13/lib-dynload:/usr/local/lib/python3.13/site-packages:/usr/lib64/python3.13/site-packages:/usr/lib/python3.13/site-packages
# Variables are taken from documentation to llama.cpp server runtime
# https://github.com/ggml-org/llama.cpp/blob/master/examples/server/README.md#usage
LLAMA_ARG_MODEL="/models/mistral-7b-instruct-v0.2.Q4_K_S.gguf"
LLAMA_ARG_ALIAS="default-model"
# -1 is syntax of python-llama
LLAMA_ARG_N_GPU_LAYERS=64
LLAMA_ARG_THREADS=12
LLAMA_ARG_BATCH=512
# Modify following var when switching model
LLAMA_ARG_CHAT_TEMPLATE="mistral-v3"
LLAMA_ARG_CTX_SIZE=32768
LLAMA_ARG_N_PARALLEL=4
# Path to Logdetective server configuration file
LOGDETECTIVE_SERVER_CONF="/config.yml"
# Authorization token for remote LLM API
# LLM_API_TOKEN="$API_SECRET"
# Path to prompts for Log Detective LLM
LOGDETECTIVE_PROMPTS="/prompts.yml"

# Database
POSTGRESQL_USER=logdetective
POSTGRESQL_PASSWORD=secret-password
POSTGRESQL_DATABASE=logdetective
POSTGRESQL_PORT=5432
SQLALCHEMY_ECHO=1

# Debugging
VSCODE_DEBUG_PORT=5678
